{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing Data\n",
    "\n",
    "In this assignment you will be reading and writing data. In this folder are 3 included data files ending in `csv`, `json` and `pkl`. \n",
    "\n",
    "* data.csv\n",
    "* data.json\n",
    "* data.pkl\n",
    "\n",
    "These are different file formats that exist. You can run the following **on the command line** to see what is in each file:\n",
    "\n",
    "```sh\n",
    "head data.csv # or pkl # or json\n",
    "```\n",
    "\n",
    "You'll see that there is some method to the madness but that each file has its peculiarities. Each file contains a portion of the total dataset that consists of 100 records, so you will need to read in all of the files and combine them into some standard format with which you are comfortable.  Aim for something standard where each \"row\" is the same format.\n",
    "\n",
    "After you've standardized all of the data, report the following bits of information by writing them to a csv file labelled `question_1.csv`, `question_2.csv` etc.  In addition, show all your work in an iPython notebook.\n",
    "\n",
    "1. What are the unique countries in the dataset?\n",
    "2. What are the unique email domains in the dataset?\n",
    "3. What are the first names of everyone that does not have a P.O. Box address?\n",
    "4. What are the names of the first 5 people when you sort the data by Country?\n",
    "5. What are the names of the first 5 people when you sort the data by phone number?\n",
    "\n",
    "### Restrictions\n",
    "You should use these standard library imports\n",
    "\n",
    "```python\n",
    "import json\n",
    "import csv\n",
    "import pickle\n",
    "```\n",
    "\n",
    "Some of you may be familiar with a Python package called `pandas` which would greatly speed up this sort of file processing.  The point of this homework is to do the work manually.  You can use `pandas` to independently check your work  if you are so inclined.  Don't worry if you are not familiar with `pandas`.  We will do this homework as a class exercise using `pandas` in the near future.\n",
    "\n",
    "\n",
    "### Comments\n",
    "\n",
    "- You may use regular expressions if you wish to extract data from each row. You do not need to use them if you do not want to or see a need to.  The Python regular expression module is called `re`.\n",
    "- You may want to use the `operator` module to help in sorting.\n",
    "- There are many data structures and formats that you might use to solve this problem.  You will have to decide if you want to keep the information for each person together as one record or all the information for each of the fields together.\n",
    "\n",
    "** Hints** \n",
    "* you can put these files into sensible structures such as lists or or dictionaries. The async covers how to do this for csv and json. For pickle this might help https://wiki.python.org/moin/UsingPickle \n",
    "\n",
    "* .items() or .key() can be useful for dictionaries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the data source\n",
    "#!head data.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': '1-243-669-7472', '8': '398-8097', '4': '901-2461', '11': '1-238-336-4864', '2': '123-5058', '15': '1-960-740-2261', '18': '1-576-789-5730', '12': '1-894-978-3696', '17': '425-7583', '10': '1-930-942-2322', '13': '220-5054', '7': '227-9994', '16': '1-120-782-6047', '5': '265-1176', '14': '992-6968', '1': '155-3483', '9': '791-5111', '3': '1-637-740-7614', '6': '945-0713', '19': '1-387-932-2096'}\n"
     ]
    }
   ],
   "source": [
    "# import csv data set\n",
    "import csv\n",
    "# create a list to store the column names\n",
    "Columns = ['Name', 'Phone', 'Address', 'City', 'Country', 'Email']\n",
    "\n",
    "data_csv_read = open('data.csv','rt')\n",
    "csvin = csv.reader(data_csv_read)\n",
    "csvin_ls = list(csvin)\n",
    "# save the data in a dictionary of dictionary, keep IDs with each field\n",
    "data_csv={i:{} for i in Columns}\n",
    "\n",
    "for row in csvin_ls[1:]:\n",
    "    data_csv['Name'][row[0]]=row[1]\n",
    "    data_csv['Phone'][row[0]]=row[2]\n",
    "    data_csv['Address'][row[0]]=row[3]\n",
    "    data_csv['City'][row[0]]=row[4]\n",
    "    data_csv['Country'][row[0]]=row[5]\n",
    "    data_csv['Email'][row[0]]=row[6]\n",
    "data_csv_read.close()\n",
    "print(data_csv['Phone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'21': '939-4818', '34': '1-505-843-5401', '26': '1-328-505-0545', '25': '1-155-558-4461', '23': '828-0406', '35': '283-6921', '29': '662-7778', '24': '1-611-756-4723', '32': '988-2217', '22': '266-3123', '37': '1-609-380-9257', '33': '1-405-823-4207', '38': '1-853-288-4269', '36': '1-250-875-9104', '27': '1-757-378-4079', '20': '1-313-739-3854', '28': '793-4359', '31': '912-7242', '30': '1-788-230-1991', '39': '172-5777'}\n"
     ]
    }
   ],
   "source": [
    "# import json data set\n",
    "import json\n",
    "data_json_file = open('data.json','rt')\n",
    "data_json = json.loads(data_json_file.read())\n",
    "data_json_file.close()\n",
    "print(data_json['Phone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{40: '420-1477', 41: '102-2189', 42: '1-790-105-7695', 43: '486-7539', 44: '1-479-861-6093', 45: '768-1000', 46: '746-8562', 47: '1-392-783-0634', 48: '1-610-717-0447', 49: '1-131-574-3183', 50: '473-1433', 51: '1-647-852-3590', 52: '514-9914', 53: '1-849-217-6292', 54: '352-3711', 55: '1-450-807-5530', 56: '1-330-764-3846', 57: '760-1654', 58: '1-722-165-1370', 59: '476-0145', 60: '477-5481', 61: '383-6541', 62: '1-600-834-9076', 63: '1-461-665-6848', 64: '370-5831', 65: '1-765-752-4793', 66: '819-2872', 67: '447-5000', 68: '1-896-767-7525', 69: '457-2683', 70: '1-228-310-1687', 71: '1-541-405-3049', 72: '143-7688', 73: '1-132-242-8605', 74: '371-7491', 75: '354-5776', 76: '461-0691', 77: '179-3944', 78: '978-6407', 79: '692-9172', 80: '1-692-738-4449', 81: '535-9704', 82: '250-6382', 83: '142-2607', 84: '1-889-203-6592', 85: '413-3678', 86: '1-731-637-5890', 87: '1-240-595-6907', 88: '979-7498', 89: '1-138-699-9182', 90: '945-1641', 91: '513-0044', 92: '1-223-433-5209', 93: '1-672-341-8336', 94: '1-790-135-9618', 95: '1-508-613-2127', 96: '397-3408', 97: '354-7392', 98: '175-7956', 99: '1-893-111-1453'}\n"
     ]
    }
   ],
   "source": [
    "# import pickle data set\n",
    "import pickle\n",
    "data_pkl = pickle.load(open(\"data.pkl\",\"rb\"))\n",
    "print(data_pkl['Phone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# create a master dictionary to combine three data sets\n",
    "master = {}\n",
    "for col in Columns:\n",
    "    master[col]= data_csv[col].copy()\n",
    "    master[col].update(data_json[col])\n",
    "    master[col].update(data_pkl[col])\n",
    "print(len(master['Name'])) # 100 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# question-1: What are the unique countries in the dataset?\n",
    "country=set(master['Country'].values())\n",
    "#print(country)\n",
    "\n",
    "\n",
    "# question-2: What are the unique email domains in the dataset?\n",
    "email_ls = []\n",
    "for e in master['Email'].values():\n",
    "    if e.find('@') > 0:\n",
    "        email_ls.append(e[e.find('@')+1:len(e)])\n",
    "email=set(email_ls)\n",
    "#for e in email:\n",
    "    #print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hillary', 'Brynne', 'Zachery', 'Kessie', 'Colby', 'Thane', 'Warren', 'Cairo', 'Genevieve', 'Tatyana', 'Chloe', 'Gail', 'Morgan', 'Wing', 'Cole', 'Yardley', 'Keane', 'Flynn', 'Hanae', 'Mason', 'Timothy', 'Rana', 'Melodie', 'Eaton', 'Lucian', 'Jane', 'Yen', 'Freya', 'Rama', 'Lawrence', 'Paul', 'Cherokee', 'Michael', 'Kay', 'Arden', 'Chantale', 'Calvin', 'Walter', 'Berk', 'Cameron', 'Ariana', 'Mason', 'Jescie', 'Maggy', 'Talon', 'Devin', 'Orli', 'Rajah', 'Inez', 'Kyle', 'Selma', 'Gwendolyn', 'Gary', 'Drake', 'Blossom', 'Joan', 'Buffy', 'Walker', 'Blake', 'Charles', 'Alexandra', 'Lenore', 'Edan', 'Clayton', 'Reuben', 'Yoshio', 'Rebecca', 'Shana', 'Adara', 'Casey', 'Idona', 'Quintessa', 'Alana', 'Gabriel', 'Tara', 'Malik', 'Harding', 'Meredith']\n"
     ]
    }
   ],
   "source": [
    "# question-3: What are the first names of everyone that does not have a P.O. Box address?\n",
    "import re\n",
    "adr = master['Address'].items()\n",
    "no_pobox = {}\n",
    "id_no_pobox = []\n",
    "fn_no_pobox = []\n",
    "pattern = re.compile('P.O. Box')\n",
    "\n",
    "# create a dictionary for first name\n",
    "fn = {}\n",
    "for key, value in master['Name'].items():\n",
    "    fn[key] = value.split()[0]\n",
    "\n",
    "for i in adr:\n",
    "    m=pattern.search(i[1])\n",
    "    if not m:\n",
    "        no_pobox[i[0]]=i[1]\n",
    "# get IDs who has no po box\n",
    "for j in no_pobox.keys():\n",
    "    id_no_pobox.append(j)\n",
    "\n",
    "for i in id_no_pobox:\n",
    "    fn_no_pobox.append(fn[i])\n",
    "print(fn_no_pobox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rajah Carrillo', 'Gwendolyn Crosby', 'Edan Cortez', 'Knox L. Cash', 'Ginger Morse']\n"
     ]
    }
   ],
   "source": [
    "# question-4: What are the names of the first 5 people when you sort the data by Country? assuming acending order\n",
    "import operator\n",
    "id_country_sort = []\n",
    "temp = []\n",
    "ct=master['Country']\n",
    "\n",
    "full = master['Name']\n",
    "# sort the dictionary by value\n",
    "sorted_ct = sorted(ct.items(), key=operator.itemgetter(1))\n",
    "\n",
    "# save the keys to a list based on the value's order\n",
    "for i in sorted_ct:\n",
    "    temp.append(i[0])\n",
    "    \n",
    "# extract the first five ID\n",
    "id_country_sort = temp[0:5]\n",
    "name_country_sort =[]\n",
    "\n",
    "# using the IDs to extract names\n",
    "for i in id_country_sort:\n",
    "    name_country_sort.append(full[i])\n",
    "\n",
    "print(name_country_sort)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16', 49, 73, 89, '25']\n",
      "['Tatyana H. French', 'Jane Joyner', 'Devin L. Boone', 'Naida Guthrie', 'Casey Mcgowan']\n"
     ]
    }
   ],
   "source": [
    "# question-5: What are the names of the first 5 people when you sort the data by phone number? assuming acending order\n",
    "id_phone_sort = []\n",
    "temp2 = []\n",
    "ph=master['Phone']\n",
    "\n",
    "# sort the dictionary by value\n",
    "sorted_ph = sorted(ph.items(), key=operator.itemgetter(1))\n",
    "\n",
    "# save the keys to a list based on the value's order\n",
    "for i in sorted_ph:\n",
    "    temp2.append(i[0])\n",
    "\n",
    "# extract the first five ID\n",
    "id_phone_sort = temp2[0:5]\n",
    "\n",
    "# using the IDs to extract first names\n",
    "name_phone_sort =[]\n",
    "for i in id_phone_sort:\n",
    "    name_phone_sort.append(full[i])\n",
    "print(name_phone_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write answers to csv file\n",
    "# for better output format, create a list of list for the answer\n",
    "ans = [country,email,fn_no_pobox,name_country_sort,name_phone_sort]\n",
    "ans_id = 1\n",
    "for item in ans:\n",
    "    output = []\n",
    "    for each in item:\n",
    "        output.append([each])\n",
    "        filename = 'question_'+str(ans_id)+'.csv'\n",
    "        question_write=open(filename,'wt')\n",
    "        csvout = csv.writer(question_write)\n",
    "        csvout.writerows(output)\n",
    "        question_write.close()\n",
    "    ans_id += 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
